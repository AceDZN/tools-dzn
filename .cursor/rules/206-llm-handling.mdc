---
description: Generate content using LLM
globs: 
alwaysApply: false
---
# LLM Integration Guidelines

## Context
- When creating API endpoints that use Gemini LLM
- When generating structured content from LLM responses
- When handling responses and errors from Gemini API
- When crafting prompts for different content types

## Requirements
- Use Google Generative AI SDK with appropriate safety settings
- Always include response formatting instructions in prompts
- Handle API errors gracefully with informative messages
- Use appropriate model parameters based on content type
- Validate responses before returning to clients

## Implementation Details

### Gemini LLM Configuration

- Model: Use `gemini-2.0-flash` for fast, structured responses
- Temperature: 
  - Lower (0.3-0.5) for factual/structured content
  - Medium (0.6-0.8) for creative/narrative content
- Safety Settings: Apply appropriate content filters per feature
- Response Format: Always request JSON for consistent parsing

### Proper Prompt Structure

Always structure prompts with these sections:
1. Clear task description and context
2. Specific user inputs and parameters
3. Expected output format with examples
4. Constraints and requirements

### Error Handling Approach

- Validate API key availability before calls
- Implement timeouts for long-running requests
- Include detailed error information for debugging
- Provide fallback responses for common error scenarios
- Log errors for monitoring and improvement

## Examples

<example>
```typescript
// Proper LLM integration with Gemini
import { 
  GoogleGenerativeAI, 
  HarmCategory, 
  HarmBlockThreshold 
} from '@google/generative-ai';

// Initialize with API key from environment variable
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_AI_API_KEY || '');

// Create structured prompts with clear format instructions
function createPrompt(data) {
  return `Generate a narrative response based on:
${JSON.stringify(data, null, 2)}

Format your response as JSON with the following structure:
{
  "title": "Story title",
  "content": "Main narrative content",
  "elements": ["key", "narrative", "elements"]
}`;
}

// Configure model with appropriate parameters
async function generateContent() {
  const model = genAI.getGenerativeModel({
    model: 'gemini-1.5-flash',
    generationConfig: {
      temperature: 0.7,
      topK: 40,
      topP: 0.95,
      maxOutputTokens: 2048,
    }
  });
  
  // Apply safety settings
  const safetySettings = [
    {
      category: HarmCategory.HARM_CATEGORY_HARASSMENT,
      threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    },
    // Additional safety settings...
  ];
  
  // Generate content with proper error handling
  try {
    const result = await model.generateContent({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      safetySettings,
    });
    
    // Process and validate response
    const text = result.response.text();
    const data = JSON.parse(text);
    
    // Validate required fields
    if (!data.title || !data.content) {
      throw new Error('Invalid response structure');
    }
    
    return data;
  } catch (error) {
    console.error('Content generation failed:', error);
    // Provide informative error for clients
    throw new Error('Unable to generate content. Please try again.');
  }
}
```
This example demonstrates proper initialization, prompt formatting, safety settings, and error handling with the Gemini API.
</example>

<example type="invalid">
```typescript
// Problematic LLM integration
const genAI = new GoogleGenerativeAI("API_KEY_HERE"); // Hard-coded API key

async function generateStory() {
  const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
  
  // Vague prompt with no structure guidance
  const prompt = "Generate a story about a character";
  
  // No safety settings or error handling
  const result = await model.generateContent(prompt);
  return result.response.text();
}
```
This implementation is problematic due to hardcoded credentials, vague prompts with no format guidance, missing safety settings, and lack of error handling.
</example>

## Best Practices

1. **Prompt Templating**: Create reusable prompt templates for consistent outputs
2. **Progressive Enhancement**: Start with basic prompts and enhance them iteratively
3. **Context Management**: Keep context size manageable to avoid token limitations
4. **Response Validation**: Always validate LLM responses before using them
5. **Safety First**: Configure appropriate safety settings for all LLM calls
7. **Testing Strategy**: Create test cases for prompt variations to ensure quality
